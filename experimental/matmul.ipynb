{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "import numpy as np\n",
    "from timeit import timeit\n",
    "import torch\n",
    "\n",
    "class Matrix:\n",
    "    def __init__(self, value, rows, cols):\n",
    "        self.value = value\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        \n",
    "    def __getitem__(self, idxs):\n",
    "        return self.value[idxs[0]][idxs[1]]\n",
    "    \n",
    "    def __setitem__(self, idxs, value):\n",
    "        self.value[idxs[0]][idxs[1]] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "def matmul_python(C, A, B):\n",
    "    for m in range(C.rows):\n",
    "        for k in range(A.cols):\n",
    "            for n in range(C.cols):\n",
    "                C[m, n] += A[m, k] * B[k, n]\n",
    "\n",
    "def benchmark_matmul_python(M, N, K):\n",
    "    A = Matrix(np.array(np.random.rand(M, K)), M, K)\n",
    "    B = Matrix(np.array(np.random.rand(K, N)), K, N)\n",
    "    C = Matrix(np.array(np.zeros((M, N))), M, N)\n",
    "    secs = timeit(lambda: matmul_python(C, A, B), number=2)/2\n",
    "    gflops = ((2*M*N*K)/secs) / 1e9\n",
    "    print(gflops, \"GFLOP/s\", '\\n', secs, 'seconds')\n",
    "    return gflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001945978976863244 GFLOP/s \n",
      " 2.1553696365008364 seconds\n"
     ]
    }
   ],
   "source": [
    "benchmark_matmul_python(128,128,128).to_float64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2180149621294274 GFLOP/s \n",
      " 0.0018910170001618098 seconds\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "\n",
    "\n",
    "def matmul_python(c,a,b):\n",
    "    for i in range(c.cols):\n",
    "        c[i,:]   = (a[i,:,None] * b[:,:]).sum(axis=0) # broadcast version\n",
    "    return c\n",
    "\n",
    "M,K,N = 128,128,128\n",
    "A = Matrix(np.array(np.random.rand(M, K)), M, K)\n",
    "B = Matrix(np.array(np.random.rand(K, N)), K, N)\n",
    "C = Matrix(np.array(np.zeros((M, N))), M, N)\n",
    "secs = timeit(lambda: matmul_python(C, A, B), number=2)/2\n",
    "gflops = ((2*M*N*K)/secs) / 1e9\n",
    "print(gflops, \"GFLOP/s\", '\\n', secs, 'seconds')\n",
    "\n",
    "# IF I didn't update this the next cell didnt use new matmul ?!\n",
    "def benchmark_matmul_python(M, N, K):\n",
    "    A = Matrix(np.array(np.random.rand(M, K)), M, K)\n",
    "    B = Matrix(np.array(np.random.rand(K, N)), K, N)\n",
    "    C = Matrix(np.array(np.zeros((M, N))), M, N)\n",
    "    secs = timeit(lambda: matmul_python(C, A, B), number=2)/2\n",
    "    gflops = ((2*M*N*K)/secs) / 1e9\n",
    "    print(gflops, \"GFLOP/s\", '\\n', secs, 'seconds')\n",
    "    return gflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2364766680521035 GFLOP/s \n",
      " 0.0018754070006252732 seconds\n"
     ]
    }
   ],
   "source": [
    "# Using `list` insted of np.array is slower. \n",
    "python_gflops = benchmark_matmul_python(128,128,128).to_float64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023808392861640604 GFLOP/s \n",
      " 0.17616913600068074 seconds\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "import torch\n",
    "\n",
    "def matmul_python(A,B): return torch.einsum('ik,kj->ij', A[:,:], B[:,:])\n",
    "\n",
    "# This one need tensors\n",
    "M,K,N = 128,128,128\n",
    "A = Matrix(torch.tensor(np.random.rand(M, K)), M, K)\n",
    "B = Matrix(torch.tensor(np.random.rand(K, N)), K, N)\n",
    "C = Matrix(torch.tensor(np.zeros((M, N))), M, N)\n",
    "\n",
    "secs = timeit(lambda: matmul_python(A, B), number=2)/2\n",
    "gflops = ((2*M*N*K)/secs) / 1e9\n",
    "print(gflops, \"GFLOP/s\", '\\n', secs, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's use Mojo\n",
    "\n",
    "for mojo test, we will assume pythons\n",
    "2 GFLOP/s is the best python can do.\n",
    "\n",
    "First, let's import modules that we are going to use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark import Benchmark\n",
    "from sys.intrinsics import strided_load\n",
    "from utils.list import VariadicList\n",
    "from math import div_ceil, min\n",
    "from memory import memset_zero\n",
    "from memory.unsafe import DTypePointer\n",
    "from random import rand, random_float64\n",
    "from sys.info import simdwidthof\n",
    "from runtime.llcl import Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This exactly the same Python implementation, \n",
    "# but is infact Mojo code!\n",
    "def matmul_untyped(C, A, B):\n",
    "    for m in range(C.rows):\n",
    "        for k in range(A.cols):\n",
    "            for n in range(C.cols):\n",
    "                C[m, n] += A[m, k] * B[k, n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change our benchmark to work with mojo as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn matrix_getitem(self: object, i: object) raises -> object:\n",
    "    return self.value[i]\n",
    "\n",
    "\n",
    "fn matrix_setitem(self: object, i: object, value: object) raises -> object:\n",
    "    self.value[i] = value\n",
    "    return None\n",
    "\n",
    "\n",
    "fn matrix_append(self: object, value: object) raises -> object:\n",
    "    self.value.append(value)\n",
    "    return None\n",
    "\n",
    "\n",
    "fn matrix_init(rows: Int, cols: Int) raises -> object:\n",
    "    let value = object([])\n",
    "    return object(\n",
    "        Attr(\"value\", value), Attr(\"__getitem__\", matrix_getitem), Attr(\"__setitem__\", matrix_setitem), \n",
    "        Attr(\"rows\", rows), Attr(\"cols\", cols), Attr(\"append\", matrix_append),\n",
    "    )\n",
    "\n",
    "def benchmark_matmul_untyped(M: Int, N: Int, K: Int, python_gflops: Float64):\n",
    "    C = matrix_init(M, N)\n",
    "    A = matrix_init(M, K)\n",
    "    B = matrix_init(K, N)\n",
    "    for i in range(M):\n",
    "        c_row = object([])\n",
    "        b_row = object([])\n",
    "        a_row = object([])\n",
    "        for j in range(N):\n",
    "            c_row.append(0.0)\n",
    "            b_row.append(random_float64(-5, 5))\n",
    "            a_row.append(random_float64(-5, 5))\n",
    "        C.append(c_row)\n",
    "        B.append(b_row)\n",
    "        A.append(a_row)\n",
    "\n",
    "    @parameter\n",
    "    fn test_fn():\n",
    "        try:\n",
    "            _ = matmul_untyped(C, A, B)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    let secs = Float64(Benchmark().run[test_fn]()) / 1_000_000_000\n",
    "    _ = (A, B, C)\n",
    "    let gflops = ((2*M*N*K)/secs) / 1e9\n",
    "    let speedup : Float64 = gflops / python_gflops\n",
    "    print(gflops, \"GFLOP/s,o took:\",secs,\"s a\", speedup.value, \"x speedup over Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023230609161565729 GFLOP/s,o took: 0.18055075400000001 s a 0.010387145769689077 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "benchmark_matmul_untyped(128, 128, 128, python_gflops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to keep I'm mind that we use np.arrays in Python and I believe it is run in C. \\\n",
    "Let's try improving it.\n",
    "\n",
    "## Adding types to the Python implementation\n",
    "\n",
    "We need to define a `Matrix` struct, and we will set data type to `Float32` for conciseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Matrix:\n",
    "    var data: DTypePointer[DType.float32]\n",
    "    var rows: Int\n",
    "    var cols: Int\n",
    "\n",
    "    fn __init__(inout self, rows: Int, cols: Int):\n",
    "        self.data = DTypePointer[DType.float32].alloc(rows * cols)\n",
    "        rand(self.data, rows*cols)\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "\n",
    "    fn __del__(owned self):\n",
    "        self.data.free()\n",
    "\n",
    "    fn zero(inout self):\n",
    "        memset_zero(self.data, self.rows * self.cols)\n",
    "\n",
    "    @always_inline\n",
    "    fn __getitem__(self, y: Int, x: Int) -> Float32:\n",
    "        return self.load[1](y, x)\n",
    "\n",
    "    @always_inline\n",
    "    fn load[nelts:Int](self, y: Int, x: Int) -> SIMD[DType.float32, nelts]:\n",
    "        return self.data.simd_load[nelts](y * self.cols + x)\n",
    "\n",
    "    @always_inline\n",
    "    fn __setitem__(self, y: Int, x: Int, val: Float32):\n",
    "        return self.store[1](y, x, val)\n",
    "\n",
    "    @always_inline\n",
    "    fn store[nelts:Int](self, y: Int, x: Int, val: SIMD[DType.float32, nelts]):\n",
    "        self.data.simd_store[nelts](y * self.cols + x, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above `Matrix` type, we can effectively copy and paste the Python implementation and just add type annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that C, A, and B have types.\n",
    "fn matmul_naive(C: Matrix, A: Matrix, B: Matrix):\n",
    "    for m in range(C.rows):\n",
    "        for k in range(A.cols):\n",
    "            for n in range(C.cols):\n",
    "                C[m, n] += A[m, k] * B[k, n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to benchmark the implementations as we improve, so let’s write a helper function that will do that for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@always_inline\n",
    "fn benchmark[\n",
    "    func: fn (Matrix, Matrix, Matrix) -> None](M: Int, N: Int, K: Int, base_gflops: Float64):\n",
    "    var C = Matrix(M, N)\n",
    "    C.zero()\n",
    "    var A = Matrix(M, K)\n",
    "    var B = Matrix(K, N)\n",
    "\n",
    "    @always_inline\n",
    "    @parameter\n",
    "    fn test_fn():\n",
    "        _ = func(C, A, B)\n",
    "\n",
    "    let secs = Float64(Benchmark().run[test_fn]()) / 1_000_000_000\n",
    "    # Prevent the matrices from being freed before the benchmark run\n",
    "    _ = (A, B, C)\n",
    "    let gflops = ((2 * M * N * K) / secs) / 1e9\n",
    "    let speedup: Float64 = gflops / base_gflops\n",
    "    # print(gflops, \"GFLOP/s\", speedup, \" speedup\")\n",
    "    print(gflops, \"GFLOP/s,o took:\",secs,\"s a\", speedup.value, \"x speedup over Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for MNK size 128\n",
      "5.2443680894453806 GFLOP/s,o took: 0.00079977300000000004 s a 2.3449241230014932 x speedup over Python\n",
      "for MNK size 512\n",
      "3.4627032018395414 GFLOP/s,o took: 0.077521936 s a 1.5482849659484443 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "print(\"for MNK size 128\")\n",
    "benchmark[matmul_naive](128, 128, 128, python_gflops)\n",
    "print(\"for MNK size 512\")\n",
    "benchmark[matmul_naive](512, 512, 512, python_gflops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding type annotations gives a huge improvement compared to the untyped version.\n",
    "\n",
    "# Vectorizing the inner most loop\n",
    "\n",
    "We can do better than that, by utilizing the vector instructions.\\\n",
    "Rather than assuming a vector width, we query the `SIMD` width of the specified dtype using `sidm_width`. This makes our code portable as we transition to other hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mojo has SIMD vector types, we can vectorize the Matmul code as follows.\n",
    "\n",
    "alias nelts = simdwidthof[DType.float32]() # The SIMD vector width. ## I assume its width of a float32.\n",
    "fn matmul_vectorized(C: Matrix, A: Matrix, B: Matrix):\n",
    "    for m in range(C.rows):\n",
    "        for k in range(A.cols):\n",
    "            for nv in range(0, C.cols,nelts):\n",
    "                C.store[nelts](m, nv, C.load[nelts](m,nv) + A[m,k] * B.load[nelts](k,nv))\n",
    "\n",
    "            # Handle remaining elements with scalars.\n",
    "            for n in range(nelts * (C.cols//nelts), C.cols):\n",
    "                C[m,n] += A[m,k] + B[k,n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for MNK size 128\n",
      "32.704379761245697 GFLOP/s,o took: 0.00012824900000000001 s a 14.623170555912894 x speedup over Python\n",
      "for MNK size 512\n",
      "31.009379791509105 GFLOP/s,o took: 0.0086565889999999993 s a 13.865282045851718 x speedup over Python\n",
      "for MNK size 1024\n",
      "20.674823960115106 GFLOP/s,o took: 0.103869501 s a 9.2443727473008632 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "print(\"for MNK size 128\")\n",
    "benchmark[matmul_vectorized](128, 128, 128, python_gflops)\n",
    "print(\"for MNK size 512\")\n",
    "benchmark[matmul_vectorized](512, 512, 512, python_gflops)\n",
    "print(\"for MNK size 1024\")\n",
    "benchmark[matmul_vectorized](1024, 1024, 1024, python_gflops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization is a common optimization, and Mojo provides a higher-order function that performs vectorization for you. \\\n",
    "The `vectorize` function takes a vector width and a function which is parametric on the vector width and is going to be evaluated in a vectorized manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the code by using the builin vetorize function\n",
    "from algorithm import vectorize\n",
    "fn matmul_vectorized_1(C: Matrix, A: Matrix, B: Matrix):\n",
    "    for m in range(C.rows):\n",
    "        for k in range(A.cols):\n",
    "            @parameter\n",
    "            fn dot[nelts: Int](n: Int):\n",
    "                C.store[nelts](m, n, C.load[nelts](m,n) + A[m,k] * B.load[nelts](k,n))\n",
    "            \n",
    "            vectorize[nelts, dot](C.cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only a slight difference in terms of performance between the two implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for MNK size 128\n",
      "33.653507927338083 GFLOP/s,o took: 0.00012463200000000001 s a 15.047556009895317 x speedup over Python\n",
      "for MNK size 512\n",
      "31.519860466716477 GFLOP/s,o took: 0.0085163909999999999 s a 14.093534225943534 x speedup over Python\n",
      "for MNK size 1024\n",
      "24.845451415150997 GFLOP/s,o took: 0.086433674000000002 s a 11.109193210046119 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "print(\"for MNK size 128\")\n",
    "benchmark[matmul_vectorized_1](128, 128, 128, python_gflops)\n",
    "print(\"for MNK size 512\")\n",
    "benchmark[matmul_vectorized_1](512, 512, 512, python_gflops)\n",
    "print(\"for MNK size 1024\")\n",
    "benchmark[matmul_vectorized_1](1024, 1024, 1024, python_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@always_inline\n",
    "fn benchmark_parallel[\n",
    "    func: fn (Matrix, Matrix, Matrix, Runtime) -> None\n",
    "](M: Int, N: Int, K: Int, base_gflops: Float64):\n",
    "    var C = Matrix(M, N)\n",
    "    C.zero()\n",
    "    var A = Matrix(M, K)\n",
    "    var B = Matrix(K, N)\n",
    "\n",
    "    with Runtime() as rt:\n",
    "        @always_inline\n",
    "        @parameter\n",
    "        fn test_fn():\n",
    "            _ = func(C, A, B, rt)\n",
    "\n",
    "        let secs = Float64(Benchmark().run[test_fn]()) / 1_000_000_000\n",
    "        # Prevent the matrices from being freed before the benchmark run\n",
    "        _ = (A, B, C)\n",
    "        let gflops = ((2 * M * N * K) / secs) / 1e9\n",
    "        let speedup: Float64 = gflops / base_gflops\n",
    "        # print(gflops, \"GFLOP/s\", speedup, \" speedup\")\n",
    "        print(gflops, \"GFLOP/s,o took:\",secs,\"s a\", speedup.value, \"x speedup over Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelize the code by using the builtin parallelize function\n",
    "from algorithm import parallelize\n",
    "fn matmul_parallelized(C: Matrix, A: Matrix, B: Matrix, rt: Runtime):\n",
    "    @parameter\n",
    "    fn calc_row(m: Int):\n",
    "        for k in range(A.cols):\n",
    "            @parameter\n",
    "            fn dot[nelts : Int](n : Int):\n",
    "                C.store[nelts](m,n, C.load[nelts](m,n) + A[m,k] * B.load[nelts](k,n))\n",
    "            vectorize[nelts, dot](C.cols)\n",
    "        \n",
    "    parallelize[calc_row](rt, C.rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for MNK size 128\n",
      "33.430338583179243 GFLOP/s,o took: 0.00012546399999999999 s a 14.947769883195763 x speedup over Python\n",
      "for MNK size 512\n",
      "32.611657516401166 GFLOP/s,o took: 0.0082312730000000008 s a 14.58171148496927 x speedup over Python\n",
      "for MNK size 1024\n",
      "33.629564651126195 GFLOP/s,o took: 0.063857016000000003 s a 15.036850207973071 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "print(\"for MNK size 128\")\n",
    "benchmark_parallel[matmul_parallelized](128, 128, 128, python_gflops)\n",
    "print(\"for MNK size 512\")\n",
    "benchmark_parallel[matmul_parallelized](512, 512, 512, python_gflops)\n",
    "print(\"for MNK size 1024\")\n",
    "benchmark_parallel[matmul_parallelized](1024, 1024, 1024, python_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm import Static2DTileUnitFunc as Tile2DFunc\n",
    "# Perform 2D tiling on the iteration space defined by end_x and end_y.\n",
    "fn tile[tiled_fn: Tile2DFunc, tile_x: Int, tile_y: Int](end_x: Int, end_y: Int):\n",
    "    # Note: this assumes that ends are multiples of the tiles.\n",
    "    for y in range(0, end_y, tile_y):\n",
    "        for x in range(0, end_x, tile_x):\n",
    "            tiled_fn[tile_x, tile_y](x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above tile function to perform tiled matmul.\n",
    "fn matmul_tiled_parallelized(C: Matrix, A: Matrix, B: Matrix, rt: Runtime):\n",
    "    @parameter\n",
    "    fn calc_row(m: Int):\n",
    "        @parameter\n",
    "        fn calc_tile[tile_x: Int, tile_y: Int](x: Int, y: Int):\n",
    "            for k in range(y, y + tile_y):\n",
    "                @parameter\n",
    "                fn dot[nelts : Int,](n : Int):\n",
    "                    C.store[nelts](m,n + x, C.load[nelts](m,n+x) + A[m,k] * B.load[nelts](k,n+x))\n",
    "                vectorize[nelts, dot](tile_x)\n",
    "\n",
    "        # We hardcode the tile factor to be 4.\n",
    "        alias tile_size = 4\n",
    "        tile[calc_tile, nelts * tile_size, tile_size](A.cols, C.cols)\n",
    "\n",
    "    parallelize[calc_row](rt, C.rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for MNK size 128\n",
      "28.202120721072063 GFLOP/s,o took: 0.00014872299999999999 s a 12.610067041582495 x speedup over Python\n",
      "for MNK size 512\n",
      "33.875645101306226 GFLOP/s,o took: 0.0079241429999999998 s a 15.146880620404943 x speedup over Python\n",
      "for MNK size 1024\n",
      "40.149339254628522 GFLOP/s,o took: 0.053487396999999999 s a 17.952049233581882 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "print(\"for MNK size 128\")\n",
    "benchmark_parallel[matmul_tiled_parallelized](128, 128, 128, python_gflops)\n",
    "print(\"for MNK size 512\")\n",
    "benchmark_parallel[matmul_tiled_parallelized](512, 512, 512, python_gflops)\n",
    "print(\"for MNK size 1024\")\n",
    "benchmark_parallel[matmul_tiled_parallelized](1024, 1024, 1024, python_gflops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unroll the vectorized loop by a constant factor.\n",
    "from algorithm import vectorize_unroll\n",
    "fn matmul_tiled_unrolled_parallelized(C: Matrix, A: Matrix, B: Matrix, rt: Runtime):\n",
    "    @parameter\n",
    "    fn calc_row(m: Int):\n",
    "        @parameter\n",
    "        fn calc_tile[tile_x: Int, tile_y: Int](x: Int, y: Int):\n",
    "            for k in range(y, y + tile_y):\n",
    "                @parameter\n",
    "                fn dot[nelts : Int,](n : Int):\n",
    "                    C.store[nelts](m,n+x, C.load[nelts](m,n+x) + A[m,k] * B.load[nelts](k,n+x))\n",
    "\n",
    "                # Vectorize by nelts and unroll by tile_x/nelts\n",
    "                # Here unroll factor is 4\n",
    "                vectorize_unroll[nelts, tile_x//nelts, dot](tile_x)\n",
    "\n",
    "        alias tile_size = 4\n",
    "        tile[calc_tile, nelts*tile_size, tile_size](A.cols, C.cols)\n",
    "      \n",
    "    parallelize[calc_row](rt, C.rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for MNK size 128\n",
      "31.139501388332068 GFLOP/s,o took: 0.00013469400000000001 s a 13.923463559069244 x speedup over Python\n",
      "for MNK size 512\n",
      "35.392660421030008 GFLOP/s,o took: 0.0075844950000000001 s a 15.825186520660568 x speedup over Python\n",
      "for MNK size 1024\n",
      "37.444583085873177 GFLOP/s,o took: 0.057350983000000001 s a 16.742666543660462 x speedup over Python\n"
     ]
    }
   ],
   "source": [
    "print(\"for MNK size 128\")\n",
    "benchmark_parallel[matmul_tiled_unrolled_parallelized](128, 128, 128, python_gflops)\n",
    "print(\"for MNK size 512\")\n",
    "benchmark_parallel[matmul_tiled_unrolled_parallelized](512, 512, 512, python_gflops)\n",
    "print(\"for MNK size 1024\")\n",
    "benchmark_parallel[matmul_tiled_unrolled_parallelized](1024, 1024, 1024, python_gflops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe it's not `70_000`x times faster, but it is still a lot faster. Keep in minds that we used NumPy in python, and it is run in C(I believe). \\\n",
    "It's still much useful for debugging and testing purposes, also its version `0.3` so we might get better performance in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
